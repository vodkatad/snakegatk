# change MUTECT_DIR to work there
MUTECT_DIR="mutect_paired_st"

# right now we cp (not ln due to pcgr) the filtered vcf, TODO add pipeline here
rule all_ln_m:
    input: expand(MUTECT_DIR+"/{sample}.pass.vcf.gz", sample=TUMOR)

rule ln_m:
    input: "/scratch/Giorgio/check_VCF_calls/whole_early-late_dataset/{sample}.OK.vcf.gz"
    output: MUTECT_DIR+"/{sample}.pass.vcf.gz"
    shell:
        """
            zcat {input} | bgzip > {output}
        """
#(snakemake) egrassi@godot:/mnt/trcanmed/snaketree/prj/snakegatk/dataset/biobanca_earlylate_pdo/mutect_paired_st$ for f in *vcf.gz; do tabix $f; done

# --force-samples had to be added for biobanca early-late due to shared LMH
#bcftools merge --force-samples --missing-to-ref -m none -o {output}.vcf.tmp {input.vcf}
rule merge_targeted_st:
    input: vcf=expand(MUTECT_DIR+"/{sample}.pass.vcf.gz", sample=TUMOR), bed=SEXONS
    output: MUTECT_DIR+"/merged_targeted.vcf"
    shell:
        """
            bcftools merge --missing-to-ref -m none -o {output}.vcf.tmp {input.vcf}
            bedtools intersect -header -u -a {output}.vcf.tmp -b {input.bed} > {output}
            rm {output}.*.tmp
        """

#rule VEP:
#    input: MUTECT_DIR+"/merged_targeted.vcf"
#    output: txt=MUTECT_DIR+"/merged.vep.txt", html=MUTECT_DIR+"/merged.vep.stats.html", vcf=MUTECT_DIR+"/merged.vcf.id"
#    params: cd=VEP_CACHE_DIR
#    shell:
#        """
#             bcftools annotate -I +'%CHROM:%POS:%REF:%ALT' {input} > {output.vcf}
#             vep -i {output.vcf}  --cache --dir_cache {params.cd} --output_file {output.txt} --stats_file {output.html} --pick
#        """

rule VEP_st:
    input: MUTECT_DIR+"/merged_targeted.vcf"
    output: vcf=MUTECT_DIR+"/merged.vcf.id"
    params: cd=VEP_CACHE_DIR
    shell:
        """
             bcftools annotate -I +'%CHROM:%POS:%REF:%ALT' {input} > {output.vcf}
        """


rule vcf_to_aftable_st:
    input: MUTECT_DIR+"/merged.vcf.id"
    output: table=MUTECT_DIR+"/merged.table_nomultiallele"
    params: nsamples=len(SAMPLES), normal="NLH"
    shell:
        """
            cat {input} | grep -v "^##" |  perl -ane '@gt=splice(@F,9); $gt=""; foreach $g (@gt) {{ if ($.==1) {{$gt.=$g."\\t";}} else {{ @afs = split(":",$g); if ($afs[2] eq ".") {{$afs[2]=0;}} $gt.=$afs[2]."\\t";}} }} chop($gt) ; print $F[2]."\\t".$gt."\\n";' | grep -v "," > {output.table}.tmp
            Rscript -e 'd <- read.table("{output.table}.tmp", sep="\\t", header=T); d <- d[, !grepl("{params.normal}",colnames(d))]; write.table(d, file="{output.table}", sep="\\t", quote=F, row.names=F);'
            rm {output.table}.tmp
        """

### annovar
rule merged_bed_st:
    input: MUTECT_DIR+"/merged.table_nomultiallele"
    output: MUTECT_DIR+"/merged.bed"
    shell:
        """
            sed 1d {input} | tr ":" "\\t" | bawk '{{print $1,$2-1,$2,$3"-"$4}}' > {output}
        """

rule annovar_st:
    input: MUTECT_DIR+"/merged.bed", ANNOVAR
    output: MUTECT_DIR+"/merged.hg38_multianno.txt"
    log: MUTECT_DIR+"/merged.hg38_multianno.log"
    params: ver="hg38"
    shell:
        """
        sed 's/chr//1;' < {input[0]} | tr "-" "\\t" | bawk '{{if($5=="") {{$5="-"}} if ($4==""){{$4="-"}} b=$2+1; e=b+length($4)-1; print $1,b,e,$4,$5,$6}}' > {output}.tmp
        table_annovar.pl {output}.tmp {input[1]} --otherinfo -buildver {params.ver} -out merged -remove -protocol refGene,avsnp150,cosmic87_coding,nci60,dbnsfp35c,clinvar_20180603 -operation g,f,f,f,f,f -nastring . -polish &> {log}
        rm {output}.tmp
        mv merged.hg38_multianno.txt {output}
        """


# Caution: get entire list of samples, will need to link with QC if we ever remove failed samples, QC has still to be throughly implemented, will never be completely automatic.
# do smt based on all_metrics, also they need to be converted to xlsx (or "align/deDup_{sample}.sorted.bam.flagstat")
rule xlsx_mut_st:
    input: muts=MUTECT_DIR+'/merged_longformat_{w}tiers.tsv', samples="samples_st.tsv", genes=GENES
    output: out="{w}_af_table_samples_genes_st.xlsx"
    params: linkedname=NAME+"_{w}_af_table_samples_genes_st.xlsx"
    shell:
        """
            bawk '$6!=0' {input.muts} > {output.out}.tmp
            tsv_to_xls -i {output.out}.tmp,{input.samples},{input.genes} -s muts,samples,genes -o {output.out}
            rm -f {params.linkedname}
            ln -s {output.out} {params.linkedname}
            rm {output.out}.tmp
        """

rule samples_st:
    output: "samples_st.tsv"
    params: dir=MUTECT_DIR
    shell:
        """
            ls -1 {params.dir}/*pcgr*pass.vcf.gz |  tr "//" "\\t" | tr "." "\\t" | cut -f 2 | sort | uniq > {output} 
        """

## PCGR
rule all_pcgr_st:
    input: expand(MUTECT_DIR+"/{sample}.pcgr_acmg.grch38.snvs_indels.tiers.tsv", sample=TUMOR)

PCGR='/mnt/trcanmed/snaketree/prj/snakegatk/local/src/pcgr/'
rule pcgr_st:
    input: MUTECT_DIR+"/{sample}.pass.vcf.gz"
    output: MUTECT_DIR+"/{sample}.pcgr_acmg.grch38.snvs_indels.tiers.tsv"
    params: pcgr=PCGR, size=SIZE, assay=ASSAY, mdir=MUTECT_DIR
    shell:
        """
            python3 {params.pcgr}/pcgr.py --pcgr_dir {params.pcgr} \
            --output_dir {params.mdir} \
            --sample_id {wildcards.sample} \
            --genome_assembly grch38 \
            --conf {params.pcgr}/examples/example_COAD.toml \
            --input_vcf {input} \
            --tumor_site 9 \
            --tumor_purity 1 \
            --include_trials \
            --assay {params.assay} \
            --estimate_msi_status \
            --estimate_tmb \
            --tumor_only \
            --no_vcf_validate \
            --target_size_mb {params.size}
        """

rule pcgr_tiers_af_st:
    input: MUTECT_DIR+'/merged.table_nomultiallele'
    output: af=MUTECT_DIR+'/merged.table_nomultiallele_wtiers', genes=MUTECT_DIR+'/merged.table_nomultiallele_wtiers_annot', long_muts=MUTECT_DIR+'/merged_longformat_wtiers.tsv'
    params: mdir=MUTECT_DIR, tool=BIN_DIR+'/AFmatrix_filter_pcgr', tiers='TIER 1,TIER 2,TIER 3'
    log: MUTECT_DIR+'/merged.table_nomultiallele_wtiers.log'
    shell:
        """
            {params.tool} -m {input} -o {output.af} -g {output.genes} -w "{params.tiers}" -l {output.long_muts} -u {params.mdir} &> {log}
        """

rule pcgr_tiers_af_all_st:
    input: MUTECT_DIR+'/merged.table_nomultiallele'
    output: af=MUTECT_DIR+'/merged.table_nomultiallele_alltiers', genes=MUTECT_DIR+'/merged.table_nomultiallele_alltiers_annot', long_muts=MUTECT_DIR+'/merged_longformat_alltiers.tsv'
    params: mdir=MUTECT_DIR, tool=BIN_DIR+'/AFmatrix_filter_pcgr', tiers='TIER 1,TIER 2,TIER 3,TIER 4'
    log: MUTECT_DIR+'/merged.table_nomultiallele_alltiers.log'
    shell:
        """
            {params.tool} -m {input} -o {output.af} -g {output.genes} -w "{params.tiers}" -l {output.long_muts} -u {params.mdir} &> {log}
        """

# For WGS we set SEXONS to all the mappable regions to begin with. Will need more specific rules to compute coverage on regions with at least X coverage (and keep only muts on exons for WES)
rule size_st:
    input: SEXONS
    output: "targeted_size.txt"
    shell:
        """
            bawk 'BEGIN{{t=0}} {{t=t+($3-$2)}} END {{print t}}' {input} > {output}
        """

rule mut_burden_st:
    input: tsize="targeted_size.txt", muts=MUTECT_DIR+"/merged.table_nomultiallele"
    output: MUTECT_DIR+"/mut_burden.tsv"
    run:
        import pandas as pd
        import numpy as np
        data = pd.read_csv(input.muts, sep="\t", index_col=0)
        tot = np.count_nonzero(data > 0.1, axis=0)
        target_len = 0
        with open(input.tsize, 'r') as tsize:
            line = tsize.readline()
            target_len = float(line.rstrip())
        target_len = target_len / 1000000
        res = pd.DataFrame(data = {'totmut': tot, 'burden': tot/target_len}, index=data.columns)
        res.to_csv(output[0], sep="\t", index=True)

rule signature_st:
    input: MUTECT_DIR+"/{sample}.pass.vcf.gz"
    output: "signatures/{sample}.cosmic.fit.tsv"
    params: tool=BIN_DIR+'/mut_pat_signatures_fit_one'
    shell: 
        """
            mkdir -p signatures
            {params.tool} {input} {output} {wildcards.sample}
        """

rule all_signatures_st:
    input: expand('signatures/{sample}.cosmic.fit.tsv', sample=TUMOR)
    output: 'signatures/all_cosmic_fit.tsv'
    run:    
        import pandas as pd
        res = pd.read_csv(input[0], sep="\t")
        for i in range(1,len(input)):
            resi = pd.read_csv(input[i], sep="\t")
            res = res.merge(resi, left_index=True, right_index=True)
        res.to_csv(output[0], sep="\t")
