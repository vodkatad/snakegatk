import os
ROOT=os.environ.get('BIOINFO_ROOT')
def find_prj_root(path=os.getcwd()):
    if os.path.isfile(os.path.join(path,".PRJ_ROOT")):
        return path
    else:
        if path:
            return find_prj_root(os.path.dirname(path))
        else:
            raise Exception("Can not find the PRJ_ROOT directory")


PRJ_ROOT=find_prj_root()
TMP="/scratch/home/egrassi/"

SRC_DIR=PRJ_ROOT+'/local/src'
BIN_DIR=PRJ_ROOT+'/local/bin'
FQ_REMOVED=True
DEBUG="yes"
TYPE="WGS"
PAIRED=True
SUBSAMPLE=1 # if == 1 do not downsample (downsampling is done right after alignment and dup removal, not before calling, to also recalibrate on less data).

# Needed references and annotations
GNOMAD_TASK_DIR=ROOT+'/task/annotations/dataset/gnomad'
REF_DIR=GNOMAD_TASK_DIR
GNOMAD=GNOMAD_TASK_DIR
VEP_CACHE_DIR=ROOT+"/task/variant_annotations/dataset/VEP"
ANNOVAR=ROOT+"/task/variant_annotations/dataset/annovar/hg38/humandb/"
PON=GNOMAD_TASK_DIR+"/1000g_pon.hg38.vcf.gz"
DBSNP=GNOMAD_TASK_DIR+'/chr_All_20180418.vcf.bgz'
INTERVAL=GNOMAD_TASK_DIR+'/wgs_calling_regions.hg38.interval_list'
CALLABLE_BED=GNOMAD_TASK_DIR+'/wgs_calling_regions.hg38.bed.gz'
GCFILE=GNOMAD_TASK_DIR+'/sequenza_gc_w200.wig.gz'
# Singularity containers and occam docker images
GATK_SING="/home/egrassi/gatk4140/gatk.img" # TODO normalize singularity images paths
GATK_ODOCKER="egrassi/occamsnakes/gatk_fixedov:1"
XENOME_ODOCKER="egrassi/occamsnakes/xenome:1"
ALIGN_ODOCKER="egrassi/occamsnakes/align_recalibrate:1"
SEQUENZA_ODOCKER="egrassi/occamsnakes/sequenza:1"
VARSCAN_ODOCKER="egrassi/occamsnakes/varscan:1"
PLATYPUS_ODOCKER="egrassi/occamsnakes/platypus:1"
PLH_DOCKER="bubusettete"

XENOME_PREFIX=""
XENOME_TOOL=''
XENOME_WAIT=0
PICARD=''

## This dataset:
DATA=PRJ_ROOT+"/local/share/data/second_shipment"
FQ_XENOME_DIR="xenome"

# TODO FA LINK NMH
#data@rotpunkt:~/work/snakegatk/local/src$ ./tsv_to_json_metadata.py -i ~/Dropbox/work/evol/MA/second_shipment/samples/ss_282.txt -j /tmp/test
SAMPLES_ORIG=['PRJ0003S1_SA_L001', 'PRJ0003S2_SA_L001',"PRJ0003S45_SA_L001","PRJ0003S46_SA_L001","CRC1502NLH0000000000D03000", "PRJ0003S62_SA_L001", "CRC0327NLH0000000000D04000","PRJ0003S24_SA_L001"]
SAMPLES=['CRC0282NMH0000000000D07000', 'CRC0282LMO-0-B', "CRC1078NLH0000000000D08000","CRC1078LMO-0-B", "CRC1502NLH0000000000D03000", "CRC1502LMO-0-B", "CRC0327NLH0000000000D04000","CRC0327LMO-0-B"]
NORMAL=["CRC0282NMH0000000000D07000", "CRC1078NLH0000000000D08000","CRC1502NLH0000000000D03000","CRC0327NLH0000000000D04000"]
TUMOR=["CRC0282LMO-0-B", "CRC1078LMO-0-B","CRC1502LMO-0-B","CRC0327LMO-0-B"]

#REF=""
#SAMPLESD=[]
#SAMPS=",".join(SAMPLESD)

XENOMED_SAMPLES=[]
TRIMMED_SAMPLES=[]


FASTQ_SUFFIX="_{pair}.fastq.gz"
FASTQ_SUFFIX_XENOME="_human_{pair}.fastq"

PAIRS=['R1_001','R2_001']
PAIRS_XENOME=['1','2']
CORES=12
CORESMD=4
# TODO need to adapt to unpaired (do they exists?) reads, will need to change the all rule in the subdirs using an input function...
PATTERNED=2500 
# HiSeq4000, otherwise 100 for unpatterned
#â€“o recal.bam


### TODO REMOVE ME FOR BULK!
#AFPARAM="--default-af 0" # warning this has run with this flag set! need to rerun or at least check
AFPARAM=""
# https://gatkforums.broadinstitute.org/gatk/discussion/24633/mutect2-4-1-4-0-stats-file-with-a-negative-number#latest
# use --default-af 0 to avoid 0.5 AF calls filtering 

wildcard_constraints:
    sample="[a-zA-Z0-9]+-?[0-9]+-?[A-Z0-9]+-?[A-Z0-9]?"


CALLABLE="5:10,10:50,50:100,100:150,150:inf"
CALLABLE_STRICT="50:100,100:150,150:inf"

SPLIT=12
SPLIT_INTERVAL=GNOMAD_TASK_DIR+'/GRCh38.d1.vd1.n'+str(SPLIT)
if SPLIT >= 10:
    SPLITS=['000'+str(x) for x in range(0,10)] + ['00'+str(x) for x in range(10,SPLIT)]
else:
    SPLITS=['000'+str(x) for x in range(0, SPLIT)]

#+'-scattered.interval_list'

PLOIDY=3
PURITY=1

XENOME_PREFIX=''
XENOME_TOOL=''
XENOME_WAIT=''
PICARD='picard'

# do_like_wes.sh
#bcftools merge --missing-to-ref -m none -o mutect_paired/merged_targeted.vcf.vcf.tmp mutect_paired/CRC0282LMO-0-B.pass.vcf.gz mutect_paired/CRC1078LMO-0-B.pass.vcf.gz mutect_paired/CRC1502LMO-0-B.pass.vcf.gz mutect_paired/CRC0327LMO-0-B.pass.vcf.gz
#bedtools intersect -header -u -a mutect_paired/merged_targeted.vcf.vcf.tmp -b  ../../local/share/data/Pri_Met_pairs/xgen-exome-hyb-panel-v2-targets-hg38.targets.bed > mutect_paired/merged_targeted_exons.vcf
#rm mutect_paired/merged_targeted.vcf.*.tmp
#bcftools annotate -I +'%CHROM:%POS:%REF:%ALT' mutect_paired/merged_targeted_exons.vcf > mutect_paired/merged_exons.vcf.id
#cat mutect_paired/merged_exons.vcf.id | grep -v "^##" |  perl -ane '@gt=splice(@F,9,8); $gt=""; foreach $g (@gt) { if ($.==1) {$gt.=$g."\t";} else { @afs = split(":",$g); if ($afs[2] eq ".") {$afs[2]=0;} $gt.=$afs[2]."\t";} } chop($gt) ; print $F[2]."\t".$gt."\n";' | grep -v "," > mutect_paired/merged_exons.table_nomultiallele
        
rule size_wes:
    input: '../../local/share/data/Pri_Met_pairs/xgen-exome-hyb-panel-v2-targets-hg38.targets.bed'
    output: "wes_sequenced_size.txt"
    shell:
        """
            cat {input} | bawk 'BEGIN{{t=0}} {{t=t+($3-$2)}} END {{print t}}' > {output}
        """


rule mut_burden_wes:
    input: tsize="wes_sequenced_size.txt", muts="mutect_paired/merged_exons.table_nomultiallele"
    output: "mutect_paired/mut_burden_exons.tsv"
    run:
        import pandas as pd
        import numpy as np
        data = pd.read_csv(input.muts, sep="\t", index_col=0)
        tot = np.count_nonzero(data > 0.1, axis=0)
        target_len = 0
        with open(input.tsize, 'r') as tsize:
            line = tsize.readline()
            target_len = float(line.rstrip())
        target_len = target_len / 1000000
        res = pd.DataFrame(data = {'totmut': tot, 'burden': tot/target_len}, index=data.columns)
        res.to_csv(output[0], sep="\t", index=True)
