import os
ROOT=os.environ.get('SNAKE_ROOT')
def find_prj_root(path=os.getcwd()):
    if os.path.isfile(os.path.join(path,".PRJ_ROOT")):
        return path
    else:
        if path:
            return find_prj_root(os.path.dirname(path))
        else:
            raise Exception("Can not find the PRJ_ROOT directory")


PRJ_ROOT=find_prj_root()
TMP="/scratch/trcanmed/tmp"

SRC_DIR=PRJ_ROOT+'/local/src'
BIN_DIR=PRJ_ROOT+'/local/bin'
FQ_REMOVED=True
DEBUG="yes"
TYPE="WGS"
PAIRED=True
SUBSAMPLE=1 # if == 1 do not downsample (downsampling is done right after alignment and dup removal, not before calling, to also recalibrate on less data).

# Needed references and annotations
GNOMAD_TASK_DIR=ROOT+'/task/annotations/dataset/gnomad'
REF_DIR=GNOMAD_TASK_DIR
GNOMAD=GNOMAD_TASK_DIR
VEP_CACHE_DIR=ROOT+"/task/variant_annotations/dataset/VEP"
ANNOVAR=ROOT+"/task/variant_annotations/dataset/annovar/hg38/humandb/"
PON=GNOMAD_TASK_DIR+"/1000g_pon.hg38.vcf.gz"
DBSNP=GNOMAD_TASK_DIR+'/chr_All_20180418.vcf.bgz'
INTERVAL=GNOMAD_TASK_DIR+'/wgs_calling_regions.hg38.interval_list'
CALLABLE_BED=GNOMAD_TASK_DIR+'/wgs_calling_regions.hg38.bed.gz'
GCFILE=GNOMAD_TASK_DIR+'/sequenza_gc_w200.wig.gz'
# Singularity containers and occam docker images
GATK_SING="/home/egrassi/gatk4140/gatk.img" # TODO normalize singularity images paths
GATK_ODOCKER="egrassi/occamsnakes/gatk_fixedov:1"
XENOME_ODOCKER="egrassi/occamsnakes/xenome:1"
ALIGN_ODOCKER="egrassi/occamsnakes/align_recalibrate:1"
SEQUENZA_ODOCKER="egrassi/occamsnakes/sequenza:1"
VARSCAN_ODOCKER="egrassi/occamsnakes/varscan:1"
PLATYPUS_ODOCKER="egrassi/occamsnakes/platypus:1"
PLH_DOCKER="bubusettete"


## This dataset:
DATA=PRJ_ROOT+"/local/share/data/placeholder"
FQ_XENOME_DIR="xenome"

SAMPLES_ORIG=['', '', '', '', '','', '', '']
SAMPLES=["CRC0282LMO-0-B","CRC0327LMO-0-B","CRC0441LMO-0-B","CRC1078LMO-0-B","CRC1307LMO","CRC1502LMO-0-B","CRC1599LMO-0-B","CRC1599PRO-0-B"]


TUMOR=SAMPLES
NORMAL=[SAMPLES[0]]*len(TUMOR)


#REF=""
#SAMPLESD=[]
#SAMPS=",".join(SAMPLESD)

XENOMED_SAMPLES=[]
TRIMMED_SAMPLES=[]

FQ_XENOME_DIR="xenome"
XENOME_PREFIX=""
XENOME_TOOL=""
XENOME_WAIT=""

FASTQ_SUFFIX="_{pair}.fastq.gz"
FASTQ_SUFFIX_XENOME="_human_{pair}.fastq"

PAIRS=['R1_001','R2_001']
PAIRS_XENOME=['1','2']
CORES=12
CORESMD=4
# TODO need to adapt to unpaired (do they exists?) reads, will need to change the all rule in the subdirs using an input function...
PATTERNED=2500 
# HiSeq4000, otherwise 100 for unpatterned
#â€“o recal.bam

PICARD="picard -Xmx10g -XX:ParallelGCThreads="

### TODO REMOVE ME FOR BULK!
#AFPARAM="--default-af 0"
AFPARAM=""
# https://gatkforums.broadinstitute.org/gatk/discussion/24633/mutect2-4-1-4-0-stats-file-with-a-negative-number#latest
# use --default-af 0 to avoid 0.5 AF calls filtering 

wildcard_constraints:
    sample="[a-zA-Z0-9]+-?[A-Z0-9]+-?[A-Z0-9]+-?[A-Z0-9]+?"


CALLABLE="5:10,10:50,50:100,100:150,150:inf"
CALLABLE_STRICT="50:100,100:150,150:inf"

SPLIT=12
SPLIT_INTERVAL=GNOMAD_TASK_DIR+'/GRCh38.d1.vd1.n'+str(SPLIT)
if SPLIT >= 10:
    SPLITS=['000'+str(x) for x in range(0,10)] + ['00'+str(x) for x in range(10,SPLIT)]
else:
    SPLITS=['000'+str(x) for x in range(0, SPLIT)]

#+'-scattered.interval_list'

PLOIDY=3
PURITY=1

SIZE=3000 # the default for PCGR
ASSAY="WGS" #   "TARGETED"


#/mnt/trcanmed/snaketree/prj/snakegatk/dataset/MA_bulk

#              transpose < {output.table}.tmp | grep -v NLH  | transpose > {output.table} to get rid of matched normals in vcf_to_aftable
