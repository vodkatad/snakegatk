import os
ROOT=os.environ.get('SNAKE_ROOT')
def find_prj_root(path=os.getcwd()):
    if os.path.isfile(os.path.join(path,".PRJ_ROOT")):
        return path
    else:
        if path:
            return find_prj_root(os.path.dirname(path))
        else:
            raise Exception("Can not find the PRJ_ROOT directory")


PRJ_ROOT=find_prj_root()
TMP="/tmp"

SRC_DIR=PRJ_ROOT+'/local/src'
BIN_DIR=PRJ_ROOT+'/local/bin'
FQ_REMOVED=False
DEBUG="yes"
TYPE="WES"
PAIRED=False
SUBSAMPLE=1 # if == 1 do not downsample (downsampling is done right after alignment and dup removal, not before calling, to also recalibrate on less data).

# Needed references and annotations
GNOMAD_TASK_DIR=ROOT+'/task/annotations/dataset/gnomad'
REF_DIR=GNOMAD_TASK_DIR
GNOMAD=GNOMAD_TASK_DIR
VEP_CACHE_DIR=ROOT+"/task/variant_annotations/dataset/VEP"
ANNOVAR=ROOT+"/task/variant_annotations/dataset/annovar/hg38/humandb/"
PON=""
DBSNP=GNOMAD_TASK_DIR+'/chr_All_20180418.vcf.bgz'
INTERVAL=GNOMAD_TASK_DIR+'/wgs_calling_regions.hg38.interval_list'
GCFILE=GNOMAD_TASK_DIR+'sequenza_gc_w50.wig.gz'
CALLABLE_BED=GNOMAD_TASK_DIR+'/wgs_calling_regions.hg38.bed.gz'
# Singularity containers and occam docker images
GATK_SING="/home/egrassi/gatk4140/gatk.img" # TODO normalize singularity images paths
#GATK_ODOCKER="gitlab.c3s.unito.it:5000/egrassi/occamsnakes/gatk_fixedov:1"
GATK_ODOCKER="broadinstitute/gatk:4.2.5.0"
XENOME_ODOCKER="egrassi/occamsnakes/xenome:1"
ALIGN_ODOCKER="gitlab.c3s.unito.it:5000/egrassi/occamsnakes/align_recalibrate:1"
SEQUENZA_ODOCKER="gitlab.c3s.unito.it:5000/egrassi/occamsnakes/sequenza:1"
VARSCAN_ODOCKER="egrassi/occamsnakes/varscan:1"
PLATYPUS_ODOCKER="egrassi/occamsnakes/platypus:1"

## This dataset:
DATA='/mnt/cold1/snaketree/prj/snakegatk_real/local/share/data/WES_2023'
FQ_XENOME_DIR="xenome"


# cannot do like this due to the f* biodiversa naming, resorting to glob
# now naming is ok but for the sake of uniformity I'll generate a map and use glob
MAP=DATA+'/samples_map.tsv'

def get_orig_samples():
    import glob
    import os
    o = []
    s = []
    with open(MAP, 'r') as map:
        for line in map.readlines():
            line = line.rstrip('\n')
            elems = line.split('\t')
            lookfor = elems[0]
            pathlook = os.path.join(DATA, lookfor+"_*R1*.fastq.gz")
            found = glob.glob(pathlook)
            if len(found) == 1:
                basename = os.path.basename(found[0])
                # remove _R1_001.fastq.gz from found
                f = basename.replace('_R1_001.fastq.gz','')
                o.append(f)
                s.append(elems[1])
            else:
                print(found)
                raise Exception(elems[1]+" not found! " + pathlook)
    assert(len(o) == len(s))
    print(o)
    print(s)
    return (o, s)

SAMPLES_PAIRS = get_orig_samples()

SAMPLES_ORIG=SAMPLES_PAIRS[0]
SAMPLES=SAMPLES_PAIRS[1]

TUMOR=[] # why is this needed?
#REF=""
#SAMPLESD=[]
#SAMPS=",".join(SAMPLESD)

XENOMED_SAMPLES=SAMPLES
TRIMMED_SAMPLES=[]

FASTQ_SUFFIX="_{pair}.fastq.gz"
FASTQ_SUFFIX_XENOME="_human_{pair}.fastq"
PAIRS=['SA_L001_R1_001','SA_L001_R2_001']
PAIRS_XENOME=['1','2']
XENOME_PREFIX='/mnt/trcanmed/snaketree/task/sequences/sequences/dataset/gdc/xenomidx'
XENOME_TOOL='/mnt/trcanmed/snaketree/prj/snakegatk/local/src/gossamer/build/src/xenome'
#XENOME_WAIT=10800 #28800 # 6h for one, giving 2h bonus - 3h for 100x - gave error for 10 samples
XENOME_WAIT=28800


# https://earray.chem.agilent.com/suredesign/index.htm?sessiontimeout=true
EXONS=DATA+'/SureSelect_XT_HS2_V8_S33266340_Covered_goodchrs.bed'
SEXONS=DATA+'/SureSelect_XT_HS2_V8_S33266340_Covered_goodchrs.bed'
PROBES=''
PADDING=100


PAIRS=['R1_001','R2_001']
PAIRS_XENOME=['1','2']
CORES=4
CORESMD=4
# TODO need to adapt to unpaired (do they exists?) reads, will need to change the all rule in the subdirs using an input function...
PATTERNED=2500 
# HiSeq4000, otherwise 100 for unpatterned
#â€“o recal.bam

AFPARAM=""
#AFPARAM="--default-af 0"
# https://gatkforums.broadinstitute.org/gatk/discussion/24633/mutect2-4-1-4-0-stats-file-with-a-negative-number#latest
# use --default-af 0 to avoid 0.5 AF calls filtering 

wildcard_constraints:
    sample="[a-zA-Z0-9\-]+"


CALLABLE="5:10,10:50,50:100,100:150,150:inf"
CALLABLE_STRICT="50:100,100:150,150:inf"
PLOIDY='plh'
PURITY='plh'

#PICARD="picard -Xmx10g -XX:ParallelGCThreads={params.cores}"
PICARD="picard-tools"
FQ_TRIM_DIR="placeholder"
ADAPTERS="placeholder"

rule all_markedDup:
    input: expand("align/markedDup_{sample}.sorted.bam", sample=SAMPLES)


rule all_deDup_flagstat:
    input: expand("align/deDup_{sample}.sorted.bam.flagstat", sample=SAMPLES)

rule flagstat_dup:
    input: "align/markedDup_{sample}.sorted.bam"
    output: "align/deDup_{sample}.sorted.bam.flagstat"
    shell:
        """
            samtools view -b -F 1024 {input} | samtools flagstat - > {output}
        """

rule all_recalibrate:
    input: expand("align/realigned_{sample}.bam", sample=SAMPLES)

### version notes
#bwa 0.7.17-r1188  (godot & ulisse)
#picard 2.18.25 (godot & ulisse, picard-tools)
#fastqc 0.11.8 (godot, & ulisse)
#multiqc 1.8 (godot rnabioinfotree conda env)

#SIZE=0.4 # biobanca targeted
SIZE=34 # WES agilent sureselect
ASSAY="WES" #   "TARGETED"

GENES="genes.tsv"
NAME="WES_MARIKA"

rule g:
    output: "genes.tsv"
    shell: "echo WES > {output}"

